

\subsection{Problem Complexity}

We define problem complexity as,
\begin{align*}
H^{\tau} = \sum_{i=1}^{K}\dfrac{1}{(\Delta_{i}^{\tau})^{2}} \text{, where } \Delta_{i}^{\tau}=|r_{i}-\tau|
\end{align*}

This is same as the problem complexity defined in \cite{locatelli2016optimal} for the thresholding bandit problem and is similar to the problem complexity defined in \cite{audibert2010best} for single best arm identification.

\subsection{Lemma 1} For a given horizon $T$ and $\psi=K^{2}T$, $T_{\gamma} = \sum_{m=0}^{\gamma}\dfrac{\log(\psi T \epsilon_{m}^{2})}{\epsilon_{m}}$ is less than the allocated budget $T$, where $\gamma=0,1,...,\big\lfloor \dfrac{1}{2}\log_{2} \dfrac{T}{e}\big\rfloor$ and $\epsilon_{m}$ is initialized at $1$ and halved after very round. 

\begin{proof}
For any arbitrary round $m$, we know that the number of pulls allocated for that round is 
$n_{m} = \dfrac{\log(\psi T \epsilon_{m}^{2})}{\epsilon_{m}}$. Now, 

\begin{align*}
n_{m} &= \dfrac{2\log(\psi T \epsilon_{m}^{2})}{\epsilon_{m}}\\
&= \dfrac{2\log(\psi T) + 2\log(\epsilon_{m}^{2})}{\epsilon_{m}}
\end{align*}

Taking summation over all rounds for $m=0,1,...,\gamma$. 

\begin{align*}
T_{\gamma} &= \sum_{m=0}^{\gamma}\dfrac{2\log(\psi T) + 2\log(\epsilon_{m}^{2})}{\epsilon_{m}}\\
&= 2\log (\psi T)\sum_{m=0}^{\gamma}\dfrac{1}{\epsilon_{m}} + \sum_{m=0}^{\gamma}\dfrac{2\log (\epsilon_{m}^{2})}{\epsilon_{m}}\\
&< 2\log (\psi T)\sum_{m=0}^{\gamma}\dfrac{1}{\epsilon_{m}} + \sum_{m=0}^{\gamma}\dfrac{2}{\epsilon_{m}}\\
&= 2\log (\psi T)[1+2+2^{2}+....+2^{\gamma}] + 2[1+2+2^{2}+....+2^{\gamma}]\\
&= 2\log (\psi T)[2^{\gamma} - 1] + 2[2^{\gamma} - 1]\\
&< 2\log (\psi T)\sqrt{\dfrac{T}{e}} + 2\sqrt{\dfrac{T}{e}}\\
&= 2\sqrt{\dfrac{T}{e}}[\log (\psi T) + 1]\\
&= 2\sqrt{\dfrac{T}{e}}[2\log (K T) + 1] \text{, for } \psi=K^{2}T\\
&< T
\end{align*}


\end{proof}


\subsection{Theorem 1}

\begin{proof}

According to the algorithm, the number of rounds is $m=\lbrace 0,1,2,.. \gamma\rbrace $ where $\gamma=\big\lfloor \dfrac{1}{2}\log_{2} \dfrac{T}{e}\big\rfloor$. So, $\epsilon_{m}\geq 2^{-\gamma} = \sqrt{\dfrac{e}{T}}$. Also each round $m$ consists of $n_{m} = \dfrac{\log(\psi T \epsilon_{m}^{2})}{\epsilon_{m}}$ timesteps.

Let $c_{i}= \sqrt{\dfrac{\rho\log{(\psi T\epsilon_{m}^{2})}}{2 n_{i}}}$ denote the confidence interval, where $n_{i}$ is the number of times an arm $i$ is pulled.

At the end of any round $m$, for any arm $i$, two cases are possible.

\subsubsection{Case a}
For any arm $i$, if it is eliminated from active set $B_{m}$ then the below two events have to come true,
\begin{align}
\hat{r}_{i} + c_{m_{i}} < \tau - c_{m_{i}}, \label{eq:armelim-casea}\\
\hat{r}_{i} - c_{m_{i}} > \tau + c_{m_{i}}, \label{eq:armelim-caseb}
\end{align}

For \ref{eq:armelim-casea} we can see that it eliminates arms that have performed poorly and removes them them from $B_{m}$. Similarly, \ref{eq:armelim-caseb} eliminates arms from $B_{m}$ that have performed very well compared to threshold $\tau$.

Putting the value of $n_{m_{i}}=\dfrac{2\log{(\psi T\epsilon_{m_{i}}^{2})}}{\epsilon_{m_{i}}}$ in $c_{m_{i}}$,
\begin{align*}
c_{m_{i}}&=\sqrt{\dfrac{\rho\epsilon_{m_{i}}\log (\psi T\epsilon_{m_{i}}^{2})}{2*2 \log(\psi T\epsilon_{m_{i}}^{2})}}\\
& =\dfrac{\sqrt{\rho\epsilon_{m_{i}}}}{2}\\
& \leq \sqrt{\rho\epsilon_{m_{i}+1}} < \dfrac{\Delta_{i}}{4} \text{, as }\rho\in (0,1].
\end{align*}


Again, for ${i} \in A^{'}$ for \ref{eq:armelim-casea} elimination condition, 
\begin{align*}
\hat{r}_{i} + c_{m_{i}}&\leq r_{i} + 2c_{m_{i}} \\
&= r_{i} + 4c_{m_{i}} - 2c_{m_{i}} \\
&< r_{i} + \Delta_{i}^{\tau} - 2c_{m_{i}}\\
&= \tau -2c_{m_{i}} \\
&\leq \tau - c_{m_{i}}
\end{align*}

Also, for ${i} \in A^{'}$ for \ref{eq:armelim-caseb} elimination condition, 
\begin{align*}
\hat{r}_{i} - c_{m_{i}}&\geq r_{i} - 2c_{m_{i}} \\
&= r_{i} - 4c_{m_{i}} + 2c_{m_{i}} \\
&> r_{i} - \Delta_{i}^{\tau} + 2c_{m_{i}}\\
&\geq \tau + 2c_{m_{i}} \\
&\geq \tau + c_{m_{i}}
\end{align*}

Applying Chernoff-Hoeffding bound and considering independence of complementary of the two events in \ref{eq:armelim-casea},
  \begin{align*}
\mathbb{P}\lbrace\hat{r}^{*}\leq r^{*} - c_{m_{i}}\rbrace &\leq exp(-2c_{m_{i}}^{2}n_{m_{i}})\\
&\leq exp(-2 * \dfrac{\rho\log (\psi T\epsilon_{m_{i}}^{2})}{2 n_{m_{i}}} *n_{m_{i}})\\
&\leq \dfrac{1}{(\psi T\epsilon_{m_{i}}^{2})^{\rho}}   
  \end{align*}
  
Similarly, $\mathbb{P}\lbrace\hat{r}_{i}\geq r_{i} + c_{m_{i}}\rbrace\leq \dfrac{1}{(\psi  T\epsilon_{m_{i}}^{2})^{\rho}}$
 
Summing, the two up, the probability that a sub-optimal arm ${i}$ is not eliminated on or before $m_{i}$-th round based on the \ref{eq:armelim-casea} elimination condition is  $\bigg(\dfrac{2}{(\psi T\epsilon_{m_{i}}^{2})^{\rho}}\bigg)$. 

Also, for \ref{eq:armelim-caseb} elimination condition by applying Chernoff-Hoeffding bound and considering independence of complementary of the two events in \ref{eq:armelim-caseb} we can derive a similar bound that a sub-optimal arm ${i}$ is not eliminated on or before $m_{i}$-th by $\bigg(\dfrac{2}{(\psi T\epsilon_{m_{i}}^{2})^{\rho}}\bigg)$. 

So the total probability that an arm $i$ is eliminated from $B_{m_{i}}$ is bounded by $\bigg(\dfrac{4}{(\psi T\epsilon_{m_{i}}^{2})^{\rho}}\bigg)$. 

\subsubsection{Case b}
For any arm $i$, it is not eliminated from $B_{m}$.

	For any round $m$, for any timestep $t\in m$ an arm $k\in B_{m}$ gets pulled if,
\begin{align*}
|\hat{r}_{k} - \tau| - c_{k} < |\hat{r}_{i} - \tau| - c_{i} \text{, } \forall i\in B_{m}
\end{align*}

Now from reverse triangle inequality,
\begin{align*}
|\hat{r}_{i}(t) - r_{i}|&=|(\hat{r}_{i}(t)-\tau) - (r_{i}-\tau)|\\
&\geq ||\hat{r}_{i}(t)-\tau|-|(r_{i}-\tau)||\\
&\geq |\hat{\Delta}_{i}^{\tau}(t) - \Delta_{i}^{\tau}|
\end{align*}

\end{proof}